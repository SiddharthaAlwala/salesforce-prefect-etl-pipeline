# Salesforce â†’ Polars â†’ JSON ETL Pipeline (Prefect)

## ğŸ“Œ Overview
This project implements an ETL pipeline using [Prefect](https://www.prefect.io/) that:
1. **Extracts** data from Salesforce via SOQL and saves it to CSV.
2. **Processes** the CSV using [Polars](https://pola.rs/) for data cleaning and aggregation.
3. **Loads** the processed CSV into a JSON file.

All three steps are implemented as **Prefect tasks** and orchestrated in a **Prefect flow**.  
The flow runs **every 15 minutes** using a Prefect deployment.

---

## ğŸ§© Project Structure
sf-prefect-pipeline/
â”œâ”€â”€ tasks/
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ process.py
â”‚ â””â”€â”€ load.py
â”œâ”€â”€ flows/
â”‚ â””â”€â”€ sf_csv_polars_json_flow.py
â”œâ”€â”€ deployments/
â”‚ â””â”€â”€ apply_15min_deployment.py
â”œâ”€â”€ run_multiple_times.py
â”œâ”€â”€ data/raw/
â”œâ”€â”€ data/processed/
â””â”€â”€ data/output/

yaml
Copy code

---

## âš¡ Setup

1. **Create local environment**
```bash
conda create -p .\.conda_env python=3.11 -y
conda activate .\.conda_env
Install dependencies

bash
Copy code
python -m pip install --upgrade pip
python -m pip install prefect polars simple-salesforce python-dotenv pyarrow pandas numpy
Add Salesforce credentials
Create .env in project root:

ini
Copy code
SF_USERNAME=your_username
SF_PASSWORD=your_password
SF_TOKEN=your_security_token
SF_DOMAIN=login
â–¶ï¸ Running Manually
Run the flow 3 times for testing:

bash
Copy code
python run_multiple_times.py
â° Scheduling Every 15 Minutes
1. Start Prefect server

bash
Copy code
python -m prefect server start
2. Apply the deployment and start agent

bash
Copy code
python deployments/apply_15min_deployment.py
python -m prefect agent start -q default
3. Open Prefect UI
http://127.0.0.1:4200

âœ… Output Files
data/raw/*.csv â†’ Extracted Salesforce data

data/processed/*.csv â†’ Aggregated data

data/output/*.json â†’ Final JSON export

ğŸ“Œ Notes
The soql query can be changed in sf_csv_polars_json_flow.py to target any Salesforce object (e.g. Account, Contact, Opportunity).

Tasks have built-in retries and logging.

Handles empty CSVs gracefully without crashing.